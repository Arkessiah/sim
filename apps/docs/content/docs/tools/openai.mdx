---
title: Embeddings
description: Generate Open AI embeddings
---

import { BlockInfoCard } from "@/components/ui/block-info-card"

<BlockInfoCard 
  type="openai"
  color="#10a37f"
  icon={true}
  iconSvg={`<svg className="block-icon"
      
      
      
      viewBox='0 0 24 24'
      role='img'
      xmlns='http://www.w3.org/2000/svg'
    >
      <path
        d='M22.2819 9.8211a5.9847 5.9847 0 0 0-.5157-4.9108 6.0462 6.0462 0 0 0-6.5098-2.9A6.0651 6.0651 0 0 0 4.9807 4.1818a5.9847 5.9847 0 0 0-3.9977 2.9 6.0462 6.0462 0 0 0 .7427 7.0966 5.98 5.98 0 0 0 .511 4.9107 6.051 6.051 0 0 0 6.5146 2.9001A5.9847 5.9847 0 0 0 13.2599 24a6.0557 6.0557 0 0 0 5.7718-4.2058 5.9894 5.9894 0 0 0 3.9977-2.9001 6.0557 6.0557 0 0 0-.7475-7.0729zm-9.022 12.6081a4.4755 4.4755 0 0 1-2.8764-1.0408l.1419-.0804 4.7783-2.7582a.7948.7948 0 0 0 .3927-.6813v-6.7369l2.02 1.1686a.071.071 0 0 1 .038.052v5.5826a4.504 4.504 0 0 1-4.4945 4.4944zm-9.6607-4.1254a4.4708 4.4708 0 0 1-.5346-3.0137l.142.0852 4.783 2.7582a.7712.7712 0 0 0 .7806 0l5.8428-3.3685v2.3324a.0804.0804 0 0 1-.0332.0615L9.74 19.9502a4.4992 4.4992 0 0 1-6.1408-1.6464zM2.3408 7.8956a4.485 4.485 0 0 1 2.3655-1.9728V11.6a.7664.7664 0 0 0 .3879.6765l5.8144 3.3543-2.0201 1.1685a.0757.0757 0 0 1-.071 0l-4.8303-2.7865A4.504 4.504 0 0 1 2.3408 7.872zm16.5963 3.8558L13.1038 8.364 15.1192 7.2a.0757.0757 0 0 1 .071 0l4.8303 2.7913a4.4944 4.4944 0 0 1-.6765 8.1042v-5.6772a.79.79 0 0 0-.407-.667zm2.0107-3.0231l-.142-.0852-4.7735-2.7818a.7759.7759 0 0 0-.7854 0L9.409 9.2297V6.8974a.0662.0662 0 0 1 .0284-.0615l4.8303-2.7866a4.4992 4.4992 0 0 1 6.6802 4.66zM8.3065 12.863l-2.02-1.1638a.0804.0804 0 0 1-.038-.0567V6.0742a4.4992 4.4992 0 0 1 7.3757-3.4537l-.142.0805L8.704 5.459a.7948.7948 0 0 0-.3927.6813zm1.0976-2.3654l2.602-1.4998 2.6069 1.4998v2.9994l-2.5974 1.4997-2.6067-1.4997Z'
        fill='currentColor'
      />
    </svg>`}
/>

{/* MANUAL-CONTENT-START:intro */}
[OpenAI](https://www.openai.com) is a leading AI research and deployment company that offers a suite of powerful AI models and APIs. OpenAI provides cutting-edge technologies including large language models (like GPT-4), image generation (DALL-E), and embeddings that enable developers to build sophisticated AI-powered applications.

With OpenAI, you can:

- **Generate text**: Create human-like text for various applications using GPT models
- **Create images**: Transform text descriptions into visual content with DALL-E
- **Produce embeddings**: Convert text into numerical vectors for semantic search and analysis
- **Build AI assistants**: Develop conversational agents with specialized knowledge
- **Process and analyze data**: Extract insights and patterns from unstructured text
- **Translate languages**: Convert content between different languages with high accuracy
- **Summarize content**: Condense long-form text while preserving key information

In Sim, the OpenAI integration enables your agents to leverage these powerful AI capabilities programmatically as part of their workflows. This allows for sophisticated automation scenarios that combine natural language understanding, content generation, and semantic analysis. Your agents can generate vector embeddings from text, which are numerical representations that capture semantic meaning, enabling advanced search, classification, and recommendation systems. Additionally, through the DALL-E integration, agents can create images from text descriptions, opening up possibilities for visual content generation. This integration bridges the gap between your workflow automation and state-of-the-art AI capabilities, enabling your agents to understand context, generate relevant content, and make intelligent decisions based on semantic understanding. By connecting Sim with OpenAI, you can create agents that process information more intelligently, generate creative content, and deliver more personalized experiences to users.
{/* MANUAL-CONTENT-END */}


## Operations

### `openai_embeddings`

Generate embeddings from text using OpenAI

#### Input

| Parameter | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `input` | string | Yes | Text to generate embeddings for |
| `model` | string | No | Model to use for embeddings |
| `encodingFormat` | string | No | The format to return the embeddings in |
| `apiKey` | string | Yes | OpenAI API key |

#### Output

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `success` | boolean | Operation success status |
| `output` | object | Embeddings generation results |



## Best Practices

{/* MANUAL-CONTENT-START:bestPractices */}
When implementing the Embeddings block in your Sim.ai workflows, following established best practices ensures optimal vector generation performance and seamless integration with downstream semantic operations. The Embeddings block serves as a critical data transformation component, converting textual content into numerical vector representations that enable advanced AI operations like semantic search, similarity matching, and content clustering.

**Connection Tag Usage and Data Flow**

Proper connection tag implementation is essential for effective embeddings generation. Use `<textProcessor.cleanedText>` or `<dataExtractor.content>` as inputs to the `<embeddings1.input>` field to ensure clean, well-formatted text reaches the embedding model. The primary output `<embeddings1.embeddings>` contains the vector data that flows to downstream blocks like vector databases or similarity comparison functions.

For multi-step workflows, chain the `<embeddings1.model>` output to subsequent blocks to maintain consistency across operations. The `<embeddings1.usage>` connection tag provides token consumption data that can feed into monitoring or cost-tracking workflows. Always validate input text length before embedding generation, as exceeding model token limits will cause workflow failures.

**Workflow Architecture Patterns**

Successful embeddings workflows typically follow established architectural patterns. The **Data Ingestion → Text Processing → Embeddings → Vector Storage** pattern enables building semantic search systems where documents are processed and stored as searchable vectors. For real-time applications, implement **API Trigger → Text Extraction → Embeddings → Similarity Matching** flows that process incoming queries and find relevant content.

Content classification workflows benefit from **Webhook → Embeddings → Clustering Analysis** patterns, where incoming text automatically gets categorized based on vector similarity. For batch processing, consider **File Reader → Text Chunking → Embeddings → Database Insert** architectures that efficiently process large document collections.

**Message/Data Formatting Excellence**

Text preprocessing significantly impacts embedding quality. Remove unnecessary whitespace, normalize special characters, and ensure consistent formatting before passing content to `<embeddings1.input>`. For long documents, implement chunking strategies that split text into optimal segments, typically 500-1000 tokens, to maximize semantic coherence within each embedding.

Structure your input data validation to handle edge cases like empty strings, special characters, and multilingual content. The embedding model selection through `<embeddings1.model>` should align with your use case - text-embedding-ada-002 for general purposes, while newer models offer improved performance for specific domains. Configure the `<embeddings1.encodingFormat>` parameter based on downstream requirements, choosing between float and base64 encoding.

**Debugging and Monitoring**

Implement comprehensive monitoring using the `<embeddings1.success>` output to track generation success rates and identify failure patterns. Monitor the `<embeddings1.usage>` data to track token consumption and optimize costs, particularly important for high-volume workflows. Log embedding dimensions and verify consistency across workflow executions to prevent downstream processing errors.

Create validation checkpoints that verify embedding vector lengths match expected dimensions (1536 for ada-002). Implement fallback mechanisms for API failures using conditional logic blocks that retry with different parameters or route to alternative processing paths. Monitor response times and implement timeout handlers for workflows processing large text volumes.

**Security Considerations**

Secure API key management is critical for embeddings workflows. Store OpenAI API keys in Sim.ai's secure environment variables rather than hardcoding them in workflow configurations. Implement input sanitization to prevent sensitive data from being inadvertently processed through third-party APIs.

For workflows processing confidential content, consider implementing data masking or anonymization steps before embedding generation. Monitor API usage patterns to detect unusual activity that might indicate compromised credentials. Ensure compliance with data privacy regulations when processing personal or sensitive information through embedding models.

**Performance Optimization**

Optimize embedding generation through strategic batching and caching. Implement text preprocessing to remove redundant content and normalize input formatting, reducing token consumption. Cache frequently requested embeddings using hash-based lookup systems to avoid redundant API calls.

Configure appropriate model selection based on use case requirements - newer models offer better performance but at higher cost. For large-scale operations, implement rate limiting and queue management to stay within API limits while maintaining workflow performance. Use the `<embeddings1.usage>` data to implement dynamic batching that optimizes token efficiency.

Monitor vector generation latency and implement parallel processing patterns for independent text segments. Consider implementing similarity thresholds that filter low-quality inputs before embedding generation, improving both performance and cost efficiency in downstream semantic operations.
{/* MANUAL-CONTENT-END */}


## FAQ

{/* MANUAL-CONTENT-START:faq */}
### How do I generate embeddings from text in my Sim.ai workflow?

To generate embeddings from text, add an **Embeddings block** to your Sim.ai workflow and configure its required inputs:

#### Required Inputs

| Input | Description | Example |
|-------|-------------|---------|
| `input` | The text to convert to embeddings | `<start.text>` or `<agent1.content>` |
| `apiKey` | Your OpenAI API key | `<start.apiKey>` or environment variable |

#### Optional Inputs

| Input | Description | Default |
|-------|-------------|---------|
| `model` | OpenAI embedding model to use | `text-embedding-ada-002` |
| `encodingFormat` | Format for returned embeddings | `float` |

### What outputs can I reference from an Embeddings block in my workflow?

Every Embeddings block exposes outputs that can be referenced using connection tags:

#### Available Outputs

| Output Tag | Type | Description |
|------------|------|-------------|
| `<openai1.embeddings>` | Array | The generated embedding vectors |
| `<openai1.model>` | String | The model used for generation |
| `<openai1.usage>` | Object | Token usage statistics |
| `<openai1.success>` | Boolean | `true` if embeddings were generated successfully |
| `<openai1.output>` | Object | Complete embeddings generation results |

These values can be connected to downstream blocks for vector operations, similarity calculations, or storage.

### How do I connect text from other blocks to generate embeddings?

To process text from upstream blocks:

1. In the Embeddings block's `input` field, type `<>` to open the connection menu
2. Select the text source from available connections

#### Common Connection Patterns

```json
{
  "input": "<agent1.content>",
  "apiKey": "<start.openaiKey>"
}
```

This configuration generates embeddings from an AI agent's response for semantic analysis or vector storage.

### How do I use embeddings with vector databases or similarity calculations?

Connect Embeddings block outputs to downstream processing blocks:

#### Example Workflow Patterns

##### 1. **Text → Embeddings → Function (Similarity)**
```
Agent → Embeddings → Function
```
Use `<openai1.embeddings>` in a Function block to calculate cosine similarity between vectors.

##### 2. **API → Embeddings → Database Storage**
```
API → Embeddings → HTTP
```
Store `<openai1.embeddings>` in vector databases like Pinecone or Weaviate using HTTP requests.

##### 3. **Webhook → Embeddings → Condition**
```
Webhook → Embeddings → Condition
```
Generate embeddings and use conditional logic based on vector properties.

### Why are my embeddings not generating properly?

Troubleshoot common issues with this checklist:

#### Common Issues and Solutions

| Issue | Description | Solution |
|-------|-------------|----------|
| **Invalid API Key** | OpenAI authentication failed | Verify `<start.apiKey>` is valid and has embedding permissions |
| **Empty Input Text** | No text provided for embedding | Ensure `input` field contains text (e.g., `<agent1.content>`) |
| **Model Not Found** | Invalid model specified | Use valid models like `text-embedding-ada-002` or `text-embedding-3-small` |
| **Rate Limiting** | Too many API requests | Implement delays between requests or check usage limits |
| **Token Limit Exceeded** | Input text too long | Split large texts into smaller chunks before embedding |

### How do I process multiple texts for batch embedding generation?

For processing multiple texts, use workflow patterns with iteration or multiple Embeddings blocks:

#### Batch Processing Pattern

##### 1. **Function → Multiple Embeddings**
Use a Function block to split text into chunks, then process each with separate Embeddings blocks.

##### 2. **Webhook Array → Embeddings Loop**
```
Webhook → Function (iterate) → Embeddings → Function (collect)
```
Process arrays of text inputs by iterating through each item.

##### 3. **API Response → Embeddings → Aggregation**
```
API → Function (parse) → Embeddings → Function (combine)
```
Extract multiple texts from API responses and generate embeddings for each.

### Can I use different OpenAI embedding models in my workflow?

Yes! Configure the `model` parameter to use different OpenAI embedding models:

#### Available Models

| Model | Description | Use Case |
|-------|-------------|----------|
| `text-embedding-3-small` | Latest small model | Fast, cost-effective embeddings |
| `text-embedding-3-large` | Latest large model | High-quality embeddings |
| `text-embedding-ada-002` | Previous generation | Legacy applications |

#### Example Configuration
```json
{
  "input": "<start.text>",
  "model": "text-embedding-3-small",
  "apiKey": "<start.openaiKey>"
}
```

Reference the chosen model in downstream blocks using `<openai1.model>` for tracking and validation.
{/* MANUAL-CONTENT-END */}
