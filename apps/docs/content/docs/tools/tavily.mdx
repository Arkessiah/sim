---
title: Tavily
description: Search and extract information
---

import { BlockInfoCard } from "@/components/ui/block-info-card"

<BlockInfoCard 
  type="tavily"
  color="#0066FF"
  icon={true}
  iconSvg={`<svg className="block-icon" viewBox='0 0 600 600' xmlns='http://www.w3.org/2000/svg' >
      <path
        d='M432 291C415 294 418 313 417 326C380 328 342 327 306 328C316 344 312 368 301 381C339 384 377 383 414 384C419 393 415 404 419 412C424 419 431 422 437 421C554 393 539 314 425 290'
        fill='rgb(248,202,81)'
      />
      <path
        d='M263 87C260 88 257 89 255 93C237 121 219 147 204 174C203 184 206 191 212 195C222 198 231 196 239 197C241 238 240 277 241 316C257 307 276 309 294 308C296 273 295 234 296 199C309 196 328 200 333 183C314 149 299 103 267 83'
        fill='rgb(109,164,249)'
      />
      <path
        d='M314 356L316 354C386 355 457 354 527 355C504 385 469 400 440 421C431 421 424 418 421 411C415 402 420 389 416 383C384 371 284 406 312 358'
        fill='rgb(250,188,28)'
      />
      <path
        d='M314 356C281 405 384 369 410 384C422 388 415 402 421 409C425 417 431 420 437 420C469 400 504 384 529 360C456 355 386 356 317 355'
        fill='rgb(251,186,23)'
      />
      <path
        d='M264 325C271 325 290 329 283 339C236 384 186 436 139 482C133 481 133 477 131 474C133 477 133 481 135 482C174 490 213 472 250 466C261 447 246 435 235 426C254 406 271 389 289 372C303 352 287 324 266 326'
        fill='rgb(251,156,158)'
      />
      <path
        d='M263 327C260 328 256 328 253 330C233 348 216 367 197 384C188 381 183 371 175 368C166 367 161 369 156 372C148 409 133 447 133 482C173 430 281 366 277 323'
        fill='rgb(248,56,63)'
      />
      <path
        d='M258 326C235 341 218 365 198 382C186 376 176 360 161 368L160 369L157 369C149 378 150 391 146 401C150 391 149 379 157 370C174 359 185 376 195 385C219 365 238 337 262 325'
        fill='rgb(242,165,165)'
      />
    </svg>`}
/>

{/* MANUAL-CONTENT-START:intro */}
[Tavily](https://www.tavily.com/) is an AI-powered search API designed specifically for LLM applications. It provides reliable, real-time information retrieval capabilities with features optimized for AI use cases, including semantic search, content extraction, and structured data retrieval.

With Tavily, you can:

- **Perform contextual searches**: Get relevant results based on semantic understanding rather than just keyword matching
- **Extract structured content**: Pull specific information from web pages in a clean, usable format
- **Access real-time information**: Retrieve up-to-date data from across the web
- **Process multiple URLs simultaneously**: Extract content from several web pages in a single request
- **Receive AI-optimized results**: Get search results specifically formatted for consumption by AI systems

In Sim, the Tavily integration enables your agents to search the web and extract information as part of their workflows. This allows for sophisticated automation scenarios that require up-to-date information from the internet. Your agents can formulate search queries, retrieve relevant results, and extract content from specific web pages to inform their decision-making processes. This integration bridges the gap between your workflow automation and the vast knowledge available on the web, enabling your agents to access real-time information without manual intervention. By connecting Sim with Tavily, you can create agents that stay current with the latest information, provide more accurate responses, and deliver more value to users.
{/* MANUAL-CONTENT-END */}


## Operations

### `tavily_search`

Perform AI-powered web searches using Tavily

#### Input

| Parameter | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `query` | string | Yes | The search query to execute |
| `max_results` | number | No | Maximum number of results \(1-20\) |
| `apiKey` | string | Yes | Tavily API Key |

#### Output

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `query` | string | The search query that was executed |
| `results` | array | results output from the tool |

### `tavily_extract`

Extract raw content from multiple web pages simultaneously using Tavily

#### Input

| Parameter | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `urls` | string | Yes | URL or array of URLs to extract content from |
| `extract_depth` | string | No | The depth of extraction \(basic=1 credit/5 URLs, advanced=2 credits/5 URLs\) |
| `apiKey` | string | Yes | Tavily API Key |

#### Output

| Parameter | Type | Description |
| --------- | ---- | ----------- |
| `results` | array | The URL that was extracted |



## Best Practices

{/* MANUAL-CONTENT-START:bestPractices */}
When integrating the Tavily block into your Sim.ai workflows, following established best practices ensures reliable search performance and optimal information extraction. The Tavily block serves as a sophisticated research engine that bridges the gap between workflow automation and real-time web intelligence, enabling workflows to access current information from across the internet with AI-powered relevance filtering.

**Connection Tag Usage and Data Flow**

Effective use of connection tags maximizes the Tavily block's research capabilities within your workflows. The `<tavily1.results>` output provides structured search result data that can be directly consumed by Agent blocks for content analysis or summarization. Use `<tavily1.answer>` when you need immediate, AI-processed responses rather than raw search results, particularly effective for knowledge extraction workflows.

For content extraction workflows, connect `<tavily1.url>` to downstream blocks that require source attribution, while `<tavily1.content>` delivers the extracted text content. When chaining multiple Tavily operations, leverage `<tavily1.query>` to maintain search context across workflow stages. The `<tavily1.title>` output proves invaluable for content cataloging and reference systems.

Consider using `<agent1.content>` or `<function1.output>` to dynamically generate search queries, enabling responsive research workflows that adapt to user inputs or external data sources. This pattern creates intelligent research assistants that can modify their search strategies based on context.

**Workflow Architecture Patterns**

Successful Tavily implementations typically follow research-oriented architectural patterns. The **User Input → Agent → Tavily Search → Agent Analysis** pattern creates comprehensive research workflows where initial queries get refined by AI before searching, and results undergo intelligent analysis before presentation. This ensures both relevance and comprehension.

For content monitoring systems, implement **Schedule Trigger → Tavily Search → Function → Notification** patterns that track specific topics over time. The **API → Tavily Extract → Database Storage** pattern efficiently processes bulk URL extraction for content archiving or competitive analysis workflows.

Multi-stage research workflows benefit from **Tavily Search → Function Filter → Tavily Extract → Agent Synthesis** patterns, where initial search results undergo filtering before detailed extraction, followed by AI-powered content synthesis. This approach optimizes API usage while maintaining research depth.

**Message/Data Formatting Excellence**

Structure your search queries for optimal Tavily performance by using specific, actionable language rather than broad keywords. Frame queries as questions or specific information requests to leverage Tavily's AI-powered relevance filtering. For example, use "latest developments in quantum computing applications" instead of "quantum computing."

When processing `<tavily1.results>` arrays, implement proper error handling for empty result sets or API limitations. Structure extraction workflows to handle multiple URLs efficiently by batching requests and managing the extract_depth parameter based on content complexity requirements. Basic extraction suits most content needs while advanced extraction provides deeper analysis for complex documents.

Format extracted content appropriately for downstream consumption. Clean `<tavily1.content>` output by removing excessive whitespace and parsing structured data elements before passing to Agent blocks. This preprocessing significantly improves AI analysis accuracy and response quality.

**Debugging and Monitoring**

Implement comprehensive logging for all Tavily operations to track API usage and identify optimization opportunities. Monitor search query patterns to identify frequently requested information that could benefit from caching strategies. Track the relationship between query specificity and result relevance to refine search strategies over time.

Establish monitoring for API key usage limits and implement fallback strategies for rate limiting scenarios. Log failed searches with their queries to identify patterns in unsuccessful requests, often indicating overly broad or improperly formatted search terms. Monitor extraction success rates across different URL types to understand content accessibility patterns.

Use the `<tavily1.query>` output to validate that your dynamic query generation is producing expected search terms. Implement error handling for network timeouts and API failures to ensure workflow resilience during high-traffic periods.

**Security Considerations**

Secure your Tavily API keys using Sim.ai's credential management system rather than hardcoding them in workflow configurations. Implement input validation for user-generated search queries to prevent potential injection attacks or abuse of your API quotas. Consider implementing rate limiting for user-facing search workflows to prevent quota exhaustion.

When extracting content from URLs, validate URL formats and implement domain filtering if your use case requires restricting searches to trusted sources. Be mindful of extracted content privacy, particularly when processing URLs that might contain sensitive information or personal data.

**Performance Optimization**

Optimize API usage by carefully selecting the max_results parameter based on your specific needs rather than defaulting to maximum values. Most use cases achieve optimal results with 5-10 search results, reserving higher limits for comprehensive research scenarios.

For extraction workflows, batch URLs efficiently and choose extract_depth based on content complexity. Basic extraction provides excellent performance for standard web content, while advanced extraction should be reserved for complex documents requiring deeper analysis. This approach balances thoroughness with API cost efficiency.

Implement intelligent caching strategies for frequently requested information, particularly in workflows that might repeat similar searches. Consider using the `<tavily1.answer>` output for immediate responses while simultaneously storing `<tavily1.results>` for future reference, creating dual-purpose research workflows that serve both immediate and long-term information needs.

Structure your workflows to minimize redundant API calls by leveraging connection tags effectively across multiple blocks, ensuring that valuable search results get utilized fully before initiating additional searches.
{/* MANUAL-CONTENT-END */}


## FAQ

{/* MANUAL-CONTENT-START:faq */}
### How do I search the web using the Tavily block in my workflow?

To perform AI-powered web searches with Tavily in Sim.ai, add a **Tavily block** to your workflow and configure the `tavily_search` operation:

#### Required Inputs

| Input | Description | Example |
|-------|-------------|---------|
| `query` | Your search query | `<start.searchTerm>` or `<agent1.content>` |
| `apiKey` | Your Tavily API key | `<start.tavilyApiKey>` or environment variable |
| `max_results` | Number of results (1-20) | `5` or `<start.resultCount>` |

Connect these inputs from other blocks or use static values to execute targeted web searches within your automation.

### How do I extract content from specific websites using Tavily?

To extract raw content from web pages, configure the Tavily block with the `tavily_extract` operation:

#### Required Configuration

| Input | Description | Example |
|-------|-------------|---------|
| `urls` | Target URLs to extract from | `<start.targetUrl>` or `["https://example.com"]` |
| `apiKey` | Your Tavily API key | `<start.tavilyApiKey>` |
| `extract_depth` | Extraction level (basic/advanced) | `"basic"` for 1 credit per 5 URLs |

The `extract_depth` parameter controls cost and detail: "basic" uses 1 credit per 5 URLs while "advanced" uses 2 credits per 5 URLs for deeper content extraction.

### What outputs can I reference from a Tavily block in downstream workflow steps?

Every Tavily block provides multiple outputs that can be connected to other blocks using connection tags:

#### Available Outputs

| Output Tag | Type | Description |
|------------|------|-------------|
| `<tavily1.results>` | Array | Complete search results or extracted content array |
| `<tavily1.answer>` | String | AI-generated answer from search results |
| `<tavily1.query>` | String | The search query that was executed |
| `<tavily1.content>` | String | Extracted text content from web pages |
| `<tavily1.title>` | String | Page title from extracted content |
| `<tavily1.url>` | String | Source URL of the content |

Connect these outputs to Agent blocks, Function blocks, or other tools for further processing.

### How do I connect Tavily search results to an Agent block for analysis?

To process Tavily search results with AI analysis:

1. **Add a Tavily block** configured for search operation
2. **Add an Agent block** after the Tavily block
3. **Connect Tavily outputs** to the Agent's inputs:

#### Example Configuration

```json
Agent Block inputs:
{
  "systemPrompt": "Analyze the search results and provide a summary",
  "userPrompt": "Search results: <tavily1.results>\nAnswer: <tavily1.answer>"
}
```

This pattern enables AI-powered analysis of web search results within your workflow automation.

### Why is my Tavily search returning no results or failing?

Troubleshoot common Tavily integration issues with these solutions:

#### Common Problems and Fixes

| Issue | Cause | Solution |
|-------|-------|----------|
| **API Authentication Error** | Invalid or missing API key | Verify `<start.tavilyApiKey>` is correctly set |
| **Empty Results Array** | Query too specific or no matches | Broaden search terms in `<tavily1.query>` |
| **Max Results Error** | Invalid result count | Ensure `max_results` is between 1-20 |
| **URL Extraction Fails** | Invalid URL format | Check `urls` input contains valid HTTP/HTTPS URLs |
| **Rate Limiting** | Too many requests | Implement delays between Tavily block executions |

Check workflow execution logs for specific error messages from the Tavily API.

### Can I create automated research workflows combining Tavily with other blocks?

Yes! Tavily blocks integrate seamlessly with other Sim.ai components for automated research and content processing:

#### Popular Workflow Patterns

##### 1. **Webhook → Tavily → Agent → Response**
```
User Query → Search Web → Analyze Results → Generate Summary
```
Connect `<start.query>` to Tavily, then `<tavily1.results>` to an Agent for intelligent summarization.

##### 2. **Scheduled → Tavily → Condition → Notification**
```
Daily Trigger → Search News → Check Keywords → Send Alerts
```
Automate monitoring by searching for specific topics and triggering alerts based on findings.

##### 3. **Function → Tavily Extract → Agent → Database**
```
Process URLs → Extract Content → Summarize → Store Data
```
Extract and process content from multiple websites simultaneously using `<tavily1.content>` outputs.

##### 4. **Agent → Tavily → Agent Chain**
```
Generate Query → Search Web → Refine Results → Final Answer
```
Create multi-step research workflows where agents generate search queries and process results iteratively.

### How do I handle multiple URLs for content extraction in a single Tavily block?

For bulk content extraction from multiple URLs, configure the Tavily block's `urls` input as an array:

#### Array Input Methods

| Method | Example | Use Case |
|--------|---------|-----------|
| **Static Array** | `["https://site1.com", "https://site2.com"]` | Fixed list of URLs |
| **Dynamic Array** | `<function1.urlList>` | URLs generated by upstream blocks |
| **Single URL** | `<start.targetUrl>` | Extract from one webpage |

The `extract_depth` setting affects both cost and extraction quality across all provided URLs, with "basic" providing essential content and "advanced" delivering comprehensive text extraction.
{/* MANUAL-CONTENT-END */}
